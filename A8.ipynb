{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# [Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "Supervised fine-tuning (or SFT for short) is a crucial step in RLHF. In TRL we provide an easy-to-use API to create your SFT models and train them with few lines of code on your dataset.\n",
    "\n",
    "[Python Script](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install peft==0.7.1\n",
    "# !pip3 install trl==0.7.4\n",
    "# !pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7263f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5d2d01",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17bd7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Alpaca dataset \n",
    "import json\n",
    "# Opening JSON file\n",
    "f = open('alpaca_data.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af391e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ebfe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040b8adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output'],\n",
      "    num_rows: 52002\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Map json format with dataset package\n",
    "from datasets import Dataset\n",
    "\n",
    "# Extract instructions, input, and outputs\n",
    "instructions = [entry['instruction'] for entry in data]\n",
    "inputs = [entry['input'] for entry in data]\n",
    "outputs = [entry['output'] for entry in data]\n",
    "\n",
    "# Create a Dataset\n",
    "dataset = Dataset.from_dict({'instruction': instructions, 'input': inputs, 'output': outputs})\n",
    "\n",
    "# Print dataset info\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516ac275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Give three tips for staying healthy.',\n",
       " 'input': '',\n",
       " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea8d487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n Give three tips for staying healthy. \\n ### Response: \\n 1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n 2. Exercise regularly to keep your body active and strong. \\n 3. Get enough sleep and maintain a consistent sleep schedule.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n What are the three primary colors? \\n ### Response: \\n The three primary colors are red, blue, and yellow.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n Describe the structure of an atom. \\n ### Response: \\n An atom is made up of a nucleus, which contains protons and neutrons, surrounded by electrons that travel in orbits around the nucleus. The protons and neutrons have a positive charge, while the electrons have a negative charge, resulting in an overall neutral atom. The number of each particle determines the atomic number and the type of atom.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n How can we reduce air pollution? \\n ### Response: \\n There are a number of ways to reduce air pollution, such as shifting to renewable energy sources, encouraging the use of public transportation, prohibiting the burning of fossil fuels, implementing policies to reduce emissions from industrial sources, and implementing vehicle emissions standards. Additionally, individuals can do their part to reduce air pollution by reducing car use, avoiding burning materials such as wood, and changing to energy efficient appliances.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n Describe a time when you had to make a difficult decision. \\n ### Response: \\n I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client’s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team’s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client’s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.',\n",
       " 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request. \\n ### Instruction: \\n Identify the odd one out. \\n ### Input: \\n Twitter, Instagram, Telegram \\n ### Response: \\n Telegram']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create function for setup the instruction format\n",
    "import textwrap\n",
    "\n",
    "def formatting_prompts_func(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        # if the dataset has no input, I don't need to add input on promp\n",
    "        if len(example['input'][i])==0:\n",
    "            text = f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {example['instruction'][i]}\n",
    "            \n",
    "            ### Response: \n",
    "            {example['output'][i]}\n",
    "        \n",
    "            \"\"\"\n",
    "        # if the dataset has input, I add input on promp\n",
    "        else:\n",
    "            text = f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {example['instruction'][i]}\n",
    "            \n",
    "            ### Input: \n",
    "            {example['input'][i]}\n",
    "            \n",
    "            ### Response: \n",
    "            {example['output'][i]}\n",
    "         \n",
    "            \"\"\"\n",
    "        text = ' \\n '.join(line.strip() for line in text.split(' \\n'))\n",
    "        output_texts.append(textwrap.dedent(text).strip())\n",
    "    return output_texts\n",
    "\n",
    "#check instruction-prompt\n",
    "formatting_prompts_func(dataset[:6])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b299f9",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16f67f1-c0e4-40e9-b192-4d1a9cfbfb17",
   "metadata": {},
   "source": [
    "### Instruction-Tuning\n",
    "Train on completions only\n",
    "- Use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only.\n",
    "- Note that this works only in the case when packing=False.\n",
    "- To instantiate that collator for instruction data, pass a response template and the tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69100196-d9d8-4791-9e11-6e93f1bd7550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a38e5c61-8397-4fd6-bcc2-b5c8c929b759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "response_template = \" ### Response:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28385087-8eb8-4b83-a7dd-1313bf591b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10000/10000 [00:01<00:00, 8041.12 examples/s]\n",
      "  0%|          | 0/6250 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  8%|▊         | 500/6250 [21:51<3:24:34,  2.13s/it]Checkpoint destination directory tmp_trainer\\checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8165, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1000/6250 [42:15<3:13:54,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6838, 'learning_rate': 4.2e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1500/6250 [1:03:38<2:45:35,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5929, 'learning_rate': 3.8e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 2000/6250 [1:23:53<2:48:38,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5346, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2500/6250 [1:44:21<2:13:27,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5295, 'learning_rate': 3e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 3000/6250 [2:04:42<2:11:16,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4388, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 3500/6250 [2:24:50<1:43:45,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4476, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 4000/6250 [2:44:43<1:41:31,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4069, 'learning_rate': 1.8e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 4500/6250 [3:05:04<1:01:50,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3898, 'learning_rate': 1.4000000000000001e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 5000/6250 [3:25:19<51:41,  2.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3907, 'learning_rate': 1e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 5500/6250 [3:45:30<32:38,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3506, 'learning_rate': 6e-06, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 6000/6250 [4:05:38<09:07,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3481, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6250/6250 [4:15:39<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 15339.347, 'train_samples_per_second': 3.26, 'train_steps_per_second': 0.407, 'train_loss': 1.48797197265625, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6250, training_loss=1.48797197265625, metrics={'train_runtime': 15339.347, 'train_samples_per_second': 3.26, 'train_steps_per_second': 0.407, 'train_loss': 1.48797197265625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Trainer\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=5, #default = 3\n",
    "    output_dir = 'tmp_trainer'\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset.select(range(10000)), #since I have less time, I will train model with small size of sample (10000 samples) \n",
    "    formatting_func=formatting_prompts_func,\n",
    "    max_seq_length=256,\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "trainer.train() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86345ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "trainer.save_model(\"./saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180455f",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530c7b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\earth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for tatsu-lab/alpaca_eval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatsu-lab/alpaca_eval\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    eval: Dataset({\n",
       "        features: ['instruction', 'output', 'generator', 'dataset'],\n",
       "        num_rows: 805\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load alpaca_eval dataset \n",
    "eval_dataset = load_dataset(\"tatsu-lab/alpaca_eval\")\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8701fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset['eval'][10]['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0d3c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# create the function to generate the output text\n",
    "def generate_output(text):\n",
    "    model_name_or_path = \"./saved_model\" \n",
    "    device = \"cpu\"\n",
    "\n",
    "    saved_model = AutoModelForCausalLM.from_pretrained(model_name_or_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "    \n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate text with the model\n",
    "    output_ids = saved_model.generate(input_ids, max_length=150)\n",
    "\n",
    "    # Decode the generated output\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print()\n",
    "    print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4088c",
   "metadata": {},
   "source": [
    "Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0aca3b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "            \n",
      "            ### Instruction: \n",
      "            What year was the Yamato Battleship built? \n",
      "                    ### Response: \n",
      " The Yamato Battleship was built in the year 1789. It was built in the year 1789. It was built in the year 1789. It was built in the\n"
     ]
    }
   ],
   "source": [
    "generate_output(f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {eval_dataset['eval'][50]['instruction']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f2eae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Yamato Battleship was built in 1941.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['eval'][50]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9728d53",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fd440b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "            \n",
      "            ### Instruction: \n",
      "            How does metabolism work? \n",
      "               ### Response: \n",
      " Metabolism is the process by which metabolism works. It involves the process by which the body releases energy and stores energy. It is the process by which the body releases energy and stores energy. It is the process by\n"
     ]
    }
   ],
   "source": [
    "generate_output(f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {eval_dataset['eval'][380]['instruction']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e283daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metabolism is the process by which the body converts food into energy. It involves a series of chemical reactions that break down carbohydrates, fats, and proteins in the food and convert them into energy that the cells can use. The energy is then used for activities such as growth, repair, and movement.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['eval'][380]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793a996",
   "metadata": {},
   "source": [
    "Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "172765ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "            \n",
      "            ### Instruction: \n",
      "            Write a poem about Mike and Joe becoming millionaires by leveraging the power of AI to become the greatest Agile coaches in history. Include content from the agile manifesto. \n",
      "                  ### Response: \n",
      "              \n"
     ]
    }
   ],
   "source": [
    "generate_output(f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {eval_dataset['eval'][250]['instruction']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b724a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mike and Joe, two ambitious men\\nSet out to become millionaires in the end\\nBut they knew they couldn’t do it alone\\nSo they used the power of AI to reach their goal\\n\\nThey decided to become the greatest Agile coaches\\nAnd help people find success in their approaches\\nTheir aim was to foster collaboration\\nAnd value individuals and interactions\\n\\nWith the help of AI, their dreams came to life\\nAnd soon they were millionaires, with no strife\\nThey embraced customer collaboration\\nAnd delivered working software with iteration\\n\\nTheir focus was on responding to change\\nBy continuously improving their range\\nThey kept their systems simple and easy to use\\nSo everyone was able to benefit from the news\\n\\nMike and Joe had become quite renowned\\nFor their success as Agile coaches and their wealth had abounded\\nTheir story is still told, even today\\nOf how two men leveraged AI to make their way'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['eval'][250]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f0207",
   "metadata": {},
   "source": [
    "Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ceeeec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "            \n",
      "            ### Instruction: \n",
      "            do you think retinoid is effective on removing the acne? because I have a lot of it. \n",
      "                                               \n"
     ]
    }
   ],
   "source": [
    "generate_output(f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {eval_dataset['eval'][10]['instruction']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b98c4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, retinoids are effective in treating acne. They work by increasing cell turnover, which helps to reduce the appearance of existing acne and prevent new outbreaks. Retinoids also help to unclog pores, which in turn reduces the amount of bacteria that can cause infections. In general, retinoids help to reduce inflammation and oil production, making them a great option for those with acne.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['eval'][10]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb368463",
   "metadata": {},
   "source": [
    "Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ff26a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "            \n",
      "            ### Instruction: \n",
      "            How do I detail a car? \n",
      "                   ### Response: \n",
      "                                      \n"
     ]
    }
   ],
   "source": [
    "generate_output(f\"\"\"\n",
    "            Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "            \n",
    "            ### Instruction: \n",
    "            {eval_dataset['eval'][30]['instruction']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "90285c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Gather the necessary materials for detailing a car, such as a vacuum cleaner, microfiber towels, car wash soap, soft brush, glass cleaner, upholstery cleaner, interior wipes, wax and tire dressing.\\n\\n2. Start by vacuuming the interior of the car to remove dirt, debris, and other particles.\\n\\n3. Use a soft brush to dust the surfaces and clean the vents.\\n\\n4. Use the car wash soap and a microfiber towel to clean the exterior of the car.\\n\\n5. Apply glass cleaner to the windows and use a microfiber towel to clean them.\\n\\n6. Apply upholstery cleaner to the seats and use a microfiber towel to clean them.\\n\\n7. Use interior wipes to clean the dashboard, center console, and other interior surfaces.\\n\\n8. Apply wax to the exterior of the car to protect it from the elements.\\n\\n9. Apply tire dressing to the tires to give them a glossy finish.\\n\\n10. Clean the rims and tires to finish the detailing process.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset['eval'][30]['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7e2d31",
   "metadata": {},
   "source": [
    "From the 5 examples that I compare with the gold label (output label from the dataset), you can see that the model is not quite good since in the first 2 examples, the model generates the response that relates to the question but it is not correct information. In the last 3 examples, the model cannot generate the response. it may be caused by the model being trained with a small sample size of the dataset and a small number of epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
